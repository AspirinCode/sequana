"""Isoseq pipeline

Affiliation: Institut Pasteur @ 2018

This pipeline is part of Sequana software (sequana.readthedocs.io)
"""
import os
import sequana
from os.path import join
from sequana import snaketools as sm
sm.init("pacbio_isoseq.rules", globals())


# This must be defined before the include
configfile: "config.yaml"
__snakefile__ = srcdir(__snakefile__)

exec(open(sequana.modules["minimap2_mapping_dynamic"], "r").read())

manager = sm.PipelineManager("pacbio_isoseq", config, fastq=False)
__data__input = manager.getrawdata()


#Generate circular consensus sequence (CCS)
__ccs__input = __data__input
__ccs__output =  manager.getname("ccs", ".ccs.bam")
__ccs__log_std = "%s/logs/ccs/stdout.logs" % manager.sample
__ccs__log_err = "%s/logs/ccs/stderr.logs" % manager.sample
include: sm.modules['ccs']
#expected_output.extend(expand(__ccs__output, sample=manager.samples))


#Primer removal and demultiplexing
__lima__input = __ccs__output
__lima__output = manager.getname("lima", ".demux.ccs.bam")
__lima__barcoded_primers = config["lima"]["primers"]
__lima__log_std = "%s/logs/lima/stdout.logs" % manager.sample
__lima__log_err = "%s/logs/lima/stderr.logs" % manager.sample
include: sm.modules['lima']
#expected_output.extend(expand(__lima__output, sample=manager.samples))


#PolyA trimming
__refine__input = __ccs__output
__refine__output = manager.getname("refine", ".flnc.bam")
__refine__log_std = "%s/logs/refine/stdout.logs" % manager.sample
__refine__log_err = "%s/logs/refine/stderr.logs" % manager.sample
include: sm.modules['refine']
#expected_output.extend(expand(__refine__output, sample=manager.samples))


#Clustering and transcript clean up
__cluster__input = __refine__output
__cluster__output = manager.getname("cluster", "_unpolished.bam")
__cluster__log_std = "%s/logs/cluster/stdout.logs" % manager.sample
__cluster__log_err = "%s/logs/cluster/stderr.logs" % manager.sample
include: sm.modules['cluster']
#expected_output.extend(expand(__cluster__output, sample=manager.samples))

#Polishing
__polish__input_bam = __cluster__output
__polish__input_subreads = __data__input
__polish__output = manager.getname("polish", "_polished.bam")
__polish__output_hq = manager.getname("polish", ".hq.fastq.gz")
__polish__output_lq = manager.getname("polish", ".lq.fastq.gz")
__polish__log_std = "%s/logs/polish/stdout.logs" % manager.sample
__polish__log_err = "%s/logs/polish/stderr.logs" % manager.sample
include: sm.modules['polish']
expected_output.extend(expand(__polish__output, sample=manager.samples))

if manager.config.general.spikes:
    __minimap2_mapping_spikes__input = __polish__output_hq
    __minimap2_mapping_spikes__logs = manager.getname("minimap2", "_spikes.logs")
    __minimap2_mapping_spikes__sort = manager.getname("minimap2_mapping", "_spikes_sort.bam")
    __minimap2_mapping_spikes__output_bam = manager.getname("minimap2_mapping", "_spikes.bam")
    __minimap2_mapping_spikes__ref = config["general"]["spikes_file"]
    include: minimap2_mapping_dynamic("spikes", manager)
    expected_output.extend(expand(__minimap2_mapping_spikes__sort, sample=manager.samples))

    #extract no spike reads
    __get_no_spikes__input = manager.getname("minimap2_mapping", "_spikes.bam")
    __get_no_spikes__output = manager.getname("minimap2_mapping", "_no-spikes.fastq.gz")
    __get_no_spikes__log = manager.getname("minimap2", "no_spike.logs")
    include: sm.modules['get_no_spikes']
    expected_output.extend(expand(__get_no_spikes__output, sample=manager.samples))

    #replace all hq by all hq that don't match spikes
    __polish__output_hq = __get_no_spikes__output



#mapping with minimap2
if manager.config.minimap2_mapping.do:
    __minimap2_mapping_genome__input = __polish__output_hq
    __minimap2_mapping_genome__logs = manager.getname("minimap2", "_genome.logs")
    __minimap2_mapping_genome__sort = manager.getname("minimap2_mapping", "_sort.bam")
    __minimap2_mapping_genome__output_bam = manager.getname("minimap2_mapping", ".bam")
    __minimap2_mapping_genome__ref = config["general"]["genome_file"]
    include: minimap2_mapping_dynamic("genome", manager)
    expected_output.extend(expand(__minimap2_mapping_genome__sort, sample=manager.samples))

    if manager.config.general.annotation_file:
        __bedtools_coverage__input_bam = __minimap2_mapping_genome__output_bam
        __bedtools_coverage__input_annotation = config["general"]["annotation_file"]
        __bedtools_coverage__output = manager.getname("minimap2_mapping", "_coverage.bed")
        __bedtools_coverage__log = manager.getname("coverage", ".logs")
        include: sm.modules['bedtools_coverage']
        expected_output.extend(expand(__bedtools_coverage__output, sample=manager.samples))





# Include rule graph for each sample
__rulegraph__input = __snakefile__
__rulegraph__output = "rulegraph/rulegraph.svg"
__rulegraph__mapper = {"fastqc_samples": "fastqc_samples/"}
include: sm.modules['rulegraph']
expected_output.extend([__rulegraph__output])


# Add Conda
__conda__output = "requirements.txt"
include: sm.modules['conda']   # Create requirements.txt(dependencies)
expected_output.extend([__conda__output])


# Those rules takes a couple of seconds so no need for a cluster
localrules: conda, rulegraph

rule pacbio_isoseq:
    input: expected_output


onsuccess:
    import os
    # Create plots about stats
    sm.plot_stats(N=len(manager.samples))

    # Main directory
    report_dir_format = "%(proj)s/report_pacbio_isoseq_%(proj)s"
    for proj in manager.samples.keys():
        report_dir = report_dir_format % {"proj": proj}
        try:os.mkdir(report_dir)
        except:pass

        shell("cp %s %s" % (__snakefile__, report_dir))
        #shell("cp rulegraph.svg %s/rulegraph.svg" % (report_dir))
        shell("cp config.yaml %s" % report_dir)
        shell("cp requirements.txt %s" % report_dir)
        shell("cp snakemake_stats.png %s" % report_dir)
        try: os.mkdir("cluster_logs")
        except:pass

        try: shell("mv slurm* cluster_logs/")
        except: pass

        # Create a cleanup python file to clean a sub-directory
        sm.create_cleanup(proj)

    sm.OnSuccess()() # create instance to create main cleanup


onerror:
    print("An error occurred. See message above.")


