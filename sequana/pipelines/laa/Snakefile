import sequana
import glob
from sequana import snaketools as sm
from sequana import sequana_data

#sm.init("Snakefile", globals())

# This must be defined before the include
configfile: "config.yaml"
#__snakefile__ = srcdir(__snakefile__)
__snakefile__ = "Snakefile"
__snakefile__ = os.path.abspath(__snakefile__)


#################################### TEST
#
# do_snpeff on
#

assert config['input']['type'] in ['lima.ccs.fastq', 'lima.ccs.bam', 'subreads.bam']

# SANITY CHECKS
assert config['reference'].endswith('.fa') or config['reference'].endswith('.fasta'), \
    "Reference must be a FASTA file ending in .fa or .fasta"


do_snpeff = config['snpeff']['do']

if do_snpeff:
    assert config['snpeff']['reference'].endswith('.gbk')

# identify the pattern

ff = sm.FileFactory(config['input']['pattern'])
assert len(ff), "No files found"
if config['input']['type'] == "lima.ccs.fastq":
    for filename in ff.all_extensions:
        if "--" not in filename:
            raise ValueError("input file format must be lima_output.lbcXX--lbcXX.ccs.fastq")
        sample = filename.split("--")[0]
        if sample.startswith("lbc") is False:
            raise ValueError("input file format must be lima_output.lbcXX--lbcXX.ccs.fastq")
    samples = [sample.split('--')[0][3:] for sample in ff.all_extensions]

elif config["input"]['type'] == "lima.ccs.bam":
    pass
elif config['']:
    pass
else:
    raise ValueError("Input file type must be one of lima.ccs.fastq, lima.ccs.bam, subreads.bam")




#samples = ["{}".format(x) for x in range(25,30)]
#samples = [25, 26, 27, 29]
configfile: "config.yaml"

# Add Conda
__conda__output = "inputs/requirements.txt"
include: sm.modules['conda']   # Create requirements.txt(dependencies)



expected_output = [
        expand("bc{sample}/taxonomy/summary.html", sample=samples),
        "images/plot_ccs_histo.png",
        expand("bc{sample}/coverage.png", sample=samples),
        expand("bc{sample}/bases.txt", sample=samples),
        expand("bc{sample}/report_variant/variant_calling.html", sample=samples),
        __conda__output,
        "multiqc_report.html",
        "outputs/kraken_summary.json",
        "images/proportion_kraken.png",
        "rulegraph/rulegraph.svg"]


if do_snpeff:
    expected_output += [expand("bc{sample}/snpeff.html", sample=samples)]


rule pipeline:
    input:  expected_output


if do_snpeff:
    reference = config['reference']
    __snpeff_add_locus_in_fasta__log = "common_logs/snpeff_add_locus_in_fasta.log"
    __snpeff_add_locus_in_fasta__input = reference
    __snpeff_add_locus_in_fasta__output = "reference/{0}".format(os.path.basename(reference))
    include: sm.modules["snpeff_add_locus_in_fasta"]
    reference = __snpeff_add_locus_in_fasta__output

    # copy the genbank
    try:shell("cp {} reference/".format(config["snpeff"]['reference']))
    except:pass
else:
    # copy reference into ./reference
    reference = "reference/" + config['reference']


__freebayes__input = "bc{sample}/mapping.sorted.bam"
__freebayes__reference = reference
__freebayes__output = "bc{sample}/variants.raw.vcf"
__freebayes__log = "bc{sample}/freebayes.log"
include: sm.modules["freebayes"]


if do_snpeff:
    __snpeff__input = __freebayes__output
    __snpeff__output = "bc{sample}/variants.ann.vcf"
    __snpeff__html = "bc{sample}/snpeff.html"
    __snpeff__log = "bc{sample}/snpeff.log"
    __snpeff__csv = "bc{sample}/bc{sample}.snpeff.csv"
    include: sm.modules["snpeff"]
    __freebayes_vcf_filter__input = __snpeff__output
else:
    __freebayes_vcf_filter__input = __freebayes__output


# lima for barcode. todo


laa = False
if laa is True:
    # Looks like the input is not a CCS file but a raw bam files after lima
    # 6 mins on BC25 of project 812 so we use protected
    rule laa:
        input: PATH + "lima_output.lbc{sample}--lbc{sample}.bam"
        output: protected("bc{sample}/amplicon_analysis_summary.csv"),
        params:
            directory="bc{sample}"
        threads: 2
        shell:
            """
            cd {params.directory}
            laa --noPhasing --minLength 1000 -v --maxReads 2400  --numThreads={threads} {input}
            """


# PROJET 812
BAMPATH = "/pasteur/projets/policy01/Biomics/PacBio/smrtlink/userdata/jobs_root/001/001336/tasks/barcoding.tasks.lima-0/"

bam2ccs = False
if bam2ccs:
    rule bam2ccs:
        input: BAMPATH + "lima_output.lbc{sample}--lbc{sample}.bam"
        output: "bc{sample}/lima_output.lbc{sample}--lbc{sample}.ccs.bam"
        params:
            directory="bc{sample}"
        threads: 8
        shell:
            """
            #mkdir -p {params.directory}
            #cd {params.directory}
            ccs {input} {output} --numThreads {threads}
            """

ccs2fastq = False
if ccs2fastq:
    rule ccs2fastq:
        input: "bc{sample}/lima_output.lbc{sample}--lbc{sample}.ccs.bam"
        output: "bc{sample}/lima_output.lbc{sample}--lbc{sample}.ccs.fastq"
        shell: 
            """
            bioconvert bam2fastq {input} {output} --force
            """

rule mapping:
    input: 
        "bc{sample}/lima_output.lbc{sample}--lbc{sample}.ccs.fastq",
        reference=reference
    output: 
        "bc{sample}/mapping.sorted.bam",
        temp("bc{sample}/mapping.bam"),
        temp("bc{sample}/mapping.sam"),
    params:
        outdir = "{sample}",
        reference = reference
    threads: 4
    shell:
        """
    minimap2 -x map-pb {input.reference} {input} -t {threads}  -a > bc{params.outdir}/mapping.sam
    bioconvert sam2bam bc{params.outdir}/mapping.sam bc{params.outdir}/mapping.bam --force
    bamtools sort -in bc{params.outdir}/mapping.bam -out bc{params.outdir}/mapping.sorted.bam
        """

rule mapping_index:
        input: "bc{sample}/mapping.sorted.bam"
        output: "bc{sample}/mapping.sorted.bam.bai"
        threads: 1
        shell: "bamtools index -in {input}"


rule igv_bases:
    input: "bc{sample}/mapping.sorted.bam.bai"
    output: "bc{sample}/bases.txt"
    params:
        reference = reference
    run:
        input = input[0].replace(".bai", "")
        cmd = "igvtools count {input} stdout {params.reference} -w 1 --bases > {output}"
        shell(cmd)

"""
rule bases_plot:

    run:
        import pandas as pd
        df = pd.read_csv("bases.txt", sep="\t", skiprows=3, header=None)
        df.columns = ["Pos", "A", "C", "G", "T","N","DEL","INS"]
        df = df.set_index('Pos')
        df = df.divide(df.sum(axis=1), axis=0)
        print(df[(df>0.2).sum(axis=1)>=2])
"""

rule build_fasta:
    input: "bc{sample}/bases.txt"
    output: "bc{sample}/consensus.fasta"
    run:
        import pandas as pd
        df = pd.read_csv("bases.txt", sep="\t", skiprows=3, header=None)


# __freebayes_vcf_filter__input defined above in the do_snpeff switch
__freebayes_vcf_filter__output = "bc{sample}/variants.filtered.vcf"
__freebayes_vcf_filter__csv = "bc{sample}/variants.filtered.csv"
__freebayes_vcf_filter__report_dir = "bc{sample}/report_variant"
__freebayes_vcf_filter__html =  "bc{sample}/report_variant/variant_calling.html"
include: sm.modules["freebayes_vcf_filter"]


rule igv_count:
    input: "bc{sample}/mapping.sorted.bam.bai"
    output: "bc{sample}/coverage.txt"
    params:
        reference = reference
    run:
        input = input[0].replace(".bai", "")
        cmd = "igvtools count {input} stdout {params.reference} -w 1 > {output}"
        shell(cmd)


rule coverage:
    input: "bc{sample}/coverage.txt"
    output: "bc{sample}/coverage.png"
    run:
        from pylab import savefig, ylim, xlabel
        import pandas as pd
        df  = pd.read_csv(input[0], skiprows=2, sep="\t", index_col=0, header=None)
        df.plot(legend=False)
        ylim([0, max(ylim())])
        xlabel("position", fontsize=16)
        savefig(output[0], dpi=150)


rule plot_ccs_histo:
    input: 
        expand("bc{sample}/lima_output.lbc{sample}--lbc{sample}.ccs.fastq", sample=samples), 
    output: "images/plot_ccs_histo.png"
    run:
        from sequana import FastQ
        data = [len(FastQ(filename)) for filename in input]
        from pylab import plot, hist, savefig, xlabel
        hist(data, bins=20)
        xlabel("number of reads", fontsize=16)
        savefig(output[0], dpi=150)


if config['kraken']['do']:
    rule sequana_kraken:
        input: "bc{sample}/lima_output.lbc{sample}--lbc{sample}.ccs.fastq"
        output: "bc{sample}/taxonomy/summary.html"
        threads: 4 
        log: "bc{sample}/taxonomy/sequana_taxonomy.log"
        run:

            outdir = input[0].split("/")[0]
            cmd = "sequana_taxonomy --file1 {} "
            cmd += " --output-directory {}/taxonomy "
            cmd += " --thread {} --databases "
            cmd = cmd.format(input[0], outdir, threads)

            for this in config['kraken']['databases']:
                assert os.path.exists(this)
                cmd += " {} ".format(this)
            shell(cmd)


# TODO merge with sequana/rulegraph
__rulegraph__output="rulegraph/rulegraph.svg"

rule rulegraph:
    input: __snakefile__
    output:
        svg=__rulegraph__output,
        dot=temp("rg.dot"),
        dot2=temp("rg.ann.dot"),
    run:
        import os
        cwd = os.getcwd()
        from sequana import SequanaConfig, DOTParser
        from subprocess import Popen
        cmd = "snakemake -s {} --rulegraph --nolock ".format(input[0])
        # There is an error message caught by the PIPE
        with open("rg.dot", "w") as fl:
            p = Popen(cmd.split(), stdout=fl, stderr=subprocess.PIPE)
            p.wait()
        d = DOTParser(cwd + os.sep + output.dot)
        d.add_urls(mapper={
            "sequana_kraken": "kraken.html",
            "create_proportion_plot_kraken": "images/proportion_kraken.png",
            "plot_ccs_histo": "images/plot_ccs_histo.png"
        })
        shell("dot -Tsvg {} -o {}".format(output.dot2, output.svg))


if do_snpeff:
    rule multiqc:
        input: expand("bc{sample}/bc{sample}.snpeff.csv", sample=samples)
        output: "multiqc_report.html"
        run:
            from subprocess import Popen
            cmd = "multiqc . -f -m snpeff"
            process = Popen(cmd.split(), stderr=subprocess.PIPE, stdout=subprocess.PIPE)



rule create_proportion_plot_kraken:
    """

    barcode_name,n_reads,percent_virus,percent_human,unclassified
    bc25,8015,5985,305,537
    bc26,5184,4920,118,125
    bc27,6912,6792,109,4
    bc28,5428,5240,134,16
    bc29,7942,5878,72,1502
    """
    input: expand("bc{sample}/taxonomy/kraken/kraken.csv", sample=samples)
    output:
        image="images/proportion_kraken.png",
        data="outputs/kraken_summary.json"
    run:
        from pylab import savefig, ylim, xlabel
        import pandas as pd
        data = {}
        for sample, filename in zip(samples, input):
            assert sample in filename
            df = pd.read_csv(filename)
            data[sample] = df.groupby("kingdom")['percentage'].sum()
        df = pd.DataFrame(data)
        df.to_json(output.data)
        df = df.sort_index()
        df.T.plot(kind="bar", stacked=True)
        xlabel("Sample", fontsize=16)
        ylabel("Percentage", fontsize=16)
        savefig(output.image, dpi=200)





localrules: conda

onsuccess:

    shell("rm -f igv.log")
    from sequana.modules_report.summary import SummaryModule
    from sequana.modules_report.kraken import KrakenModule


    intro = """<p>Amplicon Analysis Summary. <br>
      <br><b>Number of samples:</b> {}
      </p>

      <img src="images/plot_ccs_histo.png"></img>
      <img src="images/proportion_kraken.png"></img>
     """

    if do_snpeff:
        intro += """<p>
        For a snpeff summary, please see this <a href="multiqc_report.html">multiqc report</html></p>
        """
        for sample in samples:
            intro += """<a href="bc{}/snpeff.html">bc{}/snpeff.html</a><br>""".format(sample, sample)

        for sample in samples:
            intro += """<a href="bc{}/report_variant/variant_calling.html">bc{}/variant report</a><br>""".format(
                sample, sample)
    else:
        "<p>No SNPEFF report available (was not required). Please see variant reports instead</p>"

    intro = intro.format(len(ff))

    data = {"inputs":None, "outputs":None, "html":None, "snakefile": __snakefile__,
          "config": "config.yaml", "stats": "stats.txt", "rulegraph": __rulegraph__output,
          "requirements": "inputs/requirements.txt"}
    s = SummaryModule(data, intro=intro)

    from sequana.utils import config as conf
    for sample in samples:
        sample_summary = {}

        conf.summary_sections = []
        conf.output_dir = "{}".format(sample)

        k = KrakenModule("bc" + sample + "/taxonomy/kraken")
        sample_summary['kraken_json'] = json.loads(k._get_stats().to_json())
        conf.summary_sections.append({
            "name": "Kraken ",
            "anchor'": "kraken",
            "content": k._get_summary_section()
        })


    from sequana.snaketools import Makefile, OnSuccess
    sm.OnSuccess()

onerror:
    print("An error occurred. See messages above.")












