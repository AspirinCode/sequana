"""ChIPseq pipeline

Affiliation: Institut Pasteur @ 2018

This pipeline is part of Sequana software (sequana.readthedocs.io)
"""
import os
import sequana
from os.path import join
from sequana import snaketools as sm

sm.init("chipseq.rules", globals())

# This must be defined before the include
configfile: "config.yaml"
__snakefile__ = srcdir(__snakefile__)

# Generic include of some dynamic modules
exec(open(sequana.modules["fastqc_dynamic"], "r").read())
exec(open(sequana.modules["bowtie2_mapping_dynamic"], "r").read())
exec(open(sequana.modules["bowtie2_index_dynamic"], "r").read())
exec(open(sequana.modules["dynamic_unpigz"], "r").read())

manager = sm.PipelineManager("chipseq", config)

__data__input = manager.getrawdata()

if manager.config.fastqc.do:
    # FASTQC on input data set
    __fastqc_raw__input_fastq = __data__input
    __fastqc_raw__output_done = "0-Fastqc/%s_fastqc_raw.done" % manager.sample
    __fastqc_raw__wkdir = "0-Fastqc"
    __fastqc_raw__log = "0-Fastqc/logs/%s_fastqc_raw.log" % manager.sample
    include: fastqc_dynamic("raw", manager)
    expected_output.extend(expand(__fastqc_raw__output_done, sample=manager.samples))

if manager.config.cutadapt.do:
    adapter_tool = manager.config.cutadapt.tool_choice

    from sequana.adapters import _get_registered_adapters as registered
    from sequana.adapters import get_sequana_adapters

    # Users may provide TruSeq, Nextera, PCRFree or other registered adapters
    fwd = manager.config.cutadapt.fwd
    if isinstance(fwd, str) and fwd in registered():
        filename = "file:" + get_sequana_adapters(fwd, "fwd")
        manager.config.cutadapt.fwd = filename

    rev = manager.config.cutadapt.rev
    if isinstance(rev, str) and rev in registered():
        filename = "file:" + get_sequana_adapters(rev, "revcomp")
        manager.config.cutadapt.rev = filename

    if adapter_tool in ["cutadapt", "atropos"]:
        adapter_tool = "cutadapt"
        __cutadapt__input_fastq = __data__input
        __cutadapt__wkdir = "1-Trimming"
        # __cutadapt__output = [manager.getname("cutadapt", "_R1_.cutadapt.fastq.gz")]
        __cutadapt__output = ["1-Trimming/%s_R1_trim.fastq.gz" % manager.sample]
        if manager.paired:
            __cutadapt__output += ["1-Trimming/%s_R2_trim.fastq.gz" % manager.sample]

        # Set the fwd and rev adapters
        __cutadapt__fwd = manager.config.cutadapt.fwd
        __cutadapt__rev = manager.config.cutadapt.rev

        __cutadapt__design = manager.config.cutadapt.design_file
        __cutadapt__design_adapter = manager.config['cutadapt']['adapter_choice']
        __cutadapt__options = manager.config.cutadapt.options
        __cutadapt__mode = manager.config.cutadapt.mode
        __cutadapt__log = "1-Trimming/logs/%s_trim.txt" % manager.sample
        __cutadapt__sample = manager.sample
        include: sm.modules["cutadapt"]

    else:
        raise ValueError("Invalid choice of cutadapt:tool in config file. Use either atropos or cutadapt")
else:
    __cutadapt__output = __data__input

if manager.config.cutadapt.do:
    # FASTQC on trimmed data set
    __fastqc_trim__input_fastq = __cutadapt__output
    __fastqc_trim__output_done = "0-Fastqc/%s_fastqc_trim.done" % manager.sample
    __fastqc_trim__wkdir = "0-Fastqc"
    __fastqc_trim__log = "0-Fastqc/logs/%s_fastqc_trim.log" % manager.sample
    include: fastqc_dynamic("trim", manager)
    expected_output.extend(expand(__fastqc_trim__output_done, sample=manager.samples))

__prefix_name__ = join(config["genome"]["genome_directory"], config["genome"]["name"])

if manager.config.genome.do:
    # indexing for bowtie2
    __bowtie2_index_ref__fasta = config["genome"]["fasta_file"]
    __bowtie2_index_ref__output_done = __prefix_name__ + ".1.bt2"
    __bowtie2_index_ref__output_prefix = __prefix_name__
    __bowtie2_index_ref__log = "2-Mapping/logs/bowtie2_ref_indexing.log"
    include: bowtie2_index_dynamic("ref")
    expected_output.extend([__bowtie2_index_ref__output_done])

if manager.config.bowtie2_mapping.do:
    # Decompress fastq.gz file before to run bowtie2
    __unpigz_R1__input = "1-Trimming/%s_R1_trim.fastq.gz" % manager.sample
    __unpigz_R1__output = "1-Trimming/%s_R1_trim.fastq" % manager.sample
    include: dynamic_unpigz("R1", manager)
    __unpigz__output = [__unpigz_R1__output]
    if manager.paired:
        __unpigz_R2__input = "1-Trimming/%s_R2_trim.fastq.gz" % manager.sample
        __unpigz_R2__output = "1-Trimming/%s_R2_trim.fastq" % manager.sample
        include: dynamic_unpigz("R2", manager)
        __unpigz__output += [__unpigz_R2__output]


    # mapping on ref
    __bowtie2_mapping_ref__input = __unpigz__output
    __bowtie2_mapping_ref__index_done = __bowtie2_index_ref__output_done
    # TODO integrer la variable genome dans le nom du bam
    __bowtie2_mapping_ref__sort = "2-Mapping/%s_ref_sort.bam" % manager.sample
    __bowtie2_mapping_ref__bam = "2-Mapping/%s_ref.bam" % manager.sample
    __bowtie2_mapping_ref__logs_err = "2-Mapping/logs/%s_ref_mapping.e" % manager.sample
    __bowtie2_mapping_ref__logs_out = "2-Mapping/logs/%s_ref_mapping.o" % manager.sample
    __bowtie2_mapping_ref__prefix_index = __bowtie2_index_ref__output_prefix
    include: bowtie2_mapping_dynamic("ref", manager)
    expected_output.extend(expand(__bowtie2_mapping_ref__sort, sample=manager.samples))

else:
    __bowtie2_mapping_ref__sort = __data__input

if manager.config.design.spike:
    # indexing for bowtie2
    __prefix_name__ = config["design"]["spike_genome_file"]
    __bowtie2_index_spike__fasta = __prefix_name__
    __bowtie2_index_spike__output_done = __prefix_name__ + ".1.bt2"
    __bowtie2_index_spike__output_prefix = __prefix_name__
    __bowtie2_index_spike__log = "2-Mapping/logs/bowtie2_spike_indexing.log"
    include: bowtie2_index_dynamic("spike")
    expected_output.extend([__bowtie2_index_spike__output_done])

    # mapping on spike
    __bowtie2_mapping_spike__input = __cutadapt__output
    __bowtie2_mapping_spike__index_done = __bowtie2_index_spike__output_done
    __bowtie2_mapping_spike__sort = "2-Mapping/%s_spike_sort.bam" % manager.sample
    __bowtie2_mapping_spike__bam = "2-Mapping/%s_spike.bam" % manager.sample
    __bowtie2_mapping_spike__logs_err = "2-Mapping/logs/%s_spike_mapping.e" % manager.sample
    __bowtie2_mapping_spike__logs_out = "2-Mapping/logs/%s_spike_mapping.o" % manager.sample
    __bowtie2_mapping_spike__prefix_index = __bowtie2_index_spike__output_prefix
    include: bowtie2_mapping_dynamic("spike", manager)
    expected_output.extend(expand(__bowtie2_mapping_spike__sort, sample=manager.samples))

# Mark duplicates
if manager.config.mark_duplicates.do:
    __mark_duplicates__input = __bowtie2_mapping_ref__sort
    __mark_duplicates__output = "3-Deduplication/%s_ref_sort_dedup.bam" % manager.sample
    __mark_duplicates__metrics = "3-Deduplication/%s_ref_sort_dedup.txt" % manager.sample
    __mark_duplicates__log_std = "3-Deduplication/logs/%s_ref_sort_dedup.e" % manager.sample
    __mark_duplicates__log_err = "3-Deduplication/logs/%s_ref_sort_dedup.e" % manager.sample
    include: sm.modules["mark_duplicates"]
    expected_output.extend(expand(__mark_duplicates__output, sample=manager.samples))

# Remove blacklist
if manager.config.remove_blacklist.do:
    __remove_blacklist__input = __mark_duplicates__output
    __remove_blacklist__output = "4-NoBlacklist/%s_ref_sort_dedup_NoBlacklist.bam" % manager.sample
    __remove_blacklist__log_std = "4-NoBlacklist/%s_ref_sort_dedup_NoBlacklist.o" % manager.sample
    __remove_blacklist__log_err = "4-NoBlacklist/%s_ref_sort_dedup_NoBlacklist.e" % manager.sample
    include: sm.modules["remove_blacklist"]
    expected_output.extend(expand(__remove_blacklist__output, sample=manager.samples))

# !Reset expected_output variable after multiqc
# Multiqc rule
__multiqc__input = expected_output
__multiqc__input_dir = "."
__multiqc__logs = "multiqc/multiqc.log"
__multiqc__output = config['multiqc']['output-directory'] + "/multiqc_report.html"
include: sm.modules["multiqc"]
expected_output = [__multiqc__output]

# Include rule graph for each sample
__rulegraph__input = __snakefile__
__rulegraph__output = "rulegraph/rulegraph.svg"
__rulegraph__mapper = {"fastqc_samples": "fastqc_samples/"}
include: sm.modules['rulegraph']
expected_output.extend([__rulegraph__output])

# Add Conda
__conda__output = "requirements.txt"
include: sm.modules['conda']  # Create requirements.txt(dependencies)
expected_output.extend([__conda__output])

# Those rules takes a couple of seconds so no need for a cluster
localrules: conda, rulegraph

rule chipseq:
    input: expected_output

onsuccess:
    import os
    # Create plots about stats
    sm.plot_stats(N=len(manager.samples))

    # Main directory
    report_dir_format = "%(proj)s/report_rnaseq_%(proj)s"
    for proj in manager.samples.keys():
        report_dir = report_dir_format % {"proj": proj}
        try:os.mkdir(report_dir)
        except:pass

        shell("cp %s %s" % (__snakefile__, report_dir))
        #shell("cp rulegraph.svg %s/rulegraph.svg" % (report_dir))
        shell("cp config.yaml %s" % report_dir)
        shell("cp requirements.txt %s" % report_dir)
        shell("cp snakemake_stats.png %s" % report_dir)
        try: os.mkdir("cluster_logs")
        except:pass

        try: shell("mv slurm* cluster_logs/")
        except: pass

        # Create a cleanup python file to clean a sub-directory
        sm.create_cleanup(proj)

    sm.OnSuccess()() # create instance to create main cleanup


onerror:
    print("An error occurred. See message above.")
