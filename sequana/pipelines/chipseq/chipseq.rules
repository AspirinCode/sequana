"""ChIPseq pipeline

Affiliation: Institut Pasteur @ 2018

This pipeline is part of Sequana software (sequana.readthedocs.io)
"""

import sequana
from os.path import join
from sequana import snaketools as sm
import pandas as pd
from fnmatch import fnmatch
from re import sub

sm.init("chipseq.rules", globals())

# This must be defined before the include
configfile: "config.yaml"
__snakefile__ = srcdir(__snakefile__)

# Generic include of some dynamic modules
exec(open(sequana.modules["fastqc_dynamic"], "r").read())
exec(open(sequana.modules["bowtie2_mapping_dynamic"], "r").read())
exec(open(sequana.modules["bowtie2_index_dynamic"], "r").read())
exec(open(sequana.modules["dynamic_unpigz"], "r").read())
exec(open(sequana.modules["macs2_dynamic"], "r").read())
exec(open(sequana.modules["preIDR_dynamic"], "r").read())


manager = sm.PipelineManager("chipseq", config)

__data__input = manager.getrawdata()


# Check the design file
__design__ = manager.config.design.design_file

design = pd.read_csv(__design__, header=0, sep='\t')



"""
REQUIREMENTS IN DESIGN:
 - all files in one directory
 - fullname of files must be :
        MARK_COND_REP_READ-TAD.fastq.gz
 - name on design must be:
        MARK_COND
 - No IDR if no replicates
 - TODO : include cases with 3 replicates
"""

#for list of input file (get_input methods)
INPUT = []
for row in design.itertuples(index=True, name='Pandas'):
    for file in manager.ff.filenames:
        mark = getattr(row, "INPUT_NAME")
        if fnmatch(file, mark+"*1_*"):
            i = 1
            name = sub(manager.ff.read_tag, '', file)
            INPUT.append(name)
            if getattr(row, "NB_INPUT") > 1 :
                while i < getattr(row, "NB_INPUT"):
                    INPUT.append(name)
                    i += 1

IP = []
for mark in design['IP_NAME']:
    for file in manager.ff.filenames:
        if fnmatch(file, mark+"*") and file not in IP:
            name = sub(manager.ff.read_tag, '', file)
            IP.append(name)


# get REP names
#get list with replicates names for all IP
rep = ['Rep1', 'Rep2']
# deduce from rep the list for SPR & PPR

# From the design file, we get only IP with more than one replicate
IP_REP = []
for row in design.itertuples(index=True, name='Pandas'):
    if getattr(row, "NB_IP") > 1:
        IP_REP.append(getattr(row, "IP_NAME"))

# We get only INPUT with more than one replicate that are linked to an IP with multiple replicates
INPUT_REP = []
for row in design.itertuples(index=True, name='Pandas'):
    if getattr(row, "NB_INPUT") > 1 and getattr(row, "NB_IP") > 1 and (getattr(row, "INPUT_NAME")) not in INPUT_REP:
        INPUT_REP.append(getattr(row, "INPUT_NAME"))

#get IP passed IDR step
IP_IDR = []
IP_SPR = {}
#IDR_REP = []
spr = ['SPR1', 'SPR2']
for cond in IP_REP:
    tmp = []
    tmp2 = []
    for ip in IP:
        name = ip.split("_Rep")
        if ip.startswith(cond):
            spr_file = sub('Rep', 'SPR', ip)
            tmp2.append(spr_file)
            tmp.append(ip)
            #IDR_REP.append("Rep"+name[1])
    IP_IDR.append(tmp)
    IP_SPR[cond] = tmp2



if manager.config.fastqc.do:
    # FASTQC on input data set
    __fastqc_raw__input_fastq = __data__input
    __fastqc_raw__output_done = "0-Fastqc/%s_fastqc_raw.done" % manager.sample
    __fastqc_raw__wkdir = "0-Fastqc"
    __fastqc_raw__log = "0-Fastqc/logs/%s_fastqc_raw.log" % manager.sample
    include: fastqc_dynamic("raw", manager)
    expected_output.extend(expand(__fastqc_raw__output_done, sample=manager.samples))

if manager.config.cutadapt.do:
    adapter_tool = manager.config.cutadapt.tool_choice

    from sequana.adapters import _get_registered_adapters as registered
    from sequana.adapters import get_sequana_adapters

    # Users may provide TruSeq, Nextera, PCRFree or other registered adapters
    fwd = manager.config.cutadapt.fwd
    if isinstance(fwd, str) and fwd in registered():
        filename = "file:" + get_sequana_adapters(fwd, "fwd")
        manager.config.cutadapt.fwd = filename

    rev = manager.config.cutadapt.rev
    if isinstance(rev, str) and rev in registered():
        filename = "file:" + get_sequana_adapters(rev, "revcomp")
        manager.config.cutadapt.rev = filename

    if adapter_tool in ["cutadapt", "atropos"]:
        adapter_tool = "cutadapt"
        __cutadapt__input_fastq = __data__input
        __cutadapt__wkdir = "1-Trimming"
        # __cutadapt__output = [manager.getname("cutadapt", "_R1_.cutadapt.fastq.gz")]
        __cutadapt__output = ["1-Trimming/%s_R1_trim.fastq.gz" % manager.sample]
        if manager.paired:
            __cutadapt__output += ["1-Trimming/%s_R2_trim.fastq.gz" % manager.sample]

        # Set the fwd and rev adapters
        __cutadapt__fwd = manager.config.cutadapt.fwd
        __cutadapt__rev = manager.config.cutadapt.rev

        __cutadapt__design = manager.config.cutadapt.design_file
        __cutadapt__design_adapter = manager.config['cutadapt']['adapter_choice']
        __cutadapt__options = manager.config.cutadapt.options
        __cutadapt__mode = manager.config.cutadapt.mode
        __cutadapt__log = "1-Trimming/logs/%s_trim.txt" % manager.sample
        __cutadapt__sample = manager.sample
        include: sm.modules["cutadapt"]

    else:
        raise ValueError("Invalid choice of cutadapt:tool in config file. Use either atropos or cutadapt")
else:
    __cutadapt__output = __data__input

if manager.config.cutadapt.do:
    # FASTQC on trimmed data set
    __fastqc_trim__input_fastq = __cutadapt__output
    __fastqc_trim__output_done = "0-Fastqc/%s_fastqc_trim.done" % manager.sample
    __fastqc_trim__wkdir = "0-Fastqc"
    __fastqc_trim__log = "0-Fastqc/logs/%s_fastqc_trim.log" % manager.sample
    include: fastqc_dynamic("trim", manager)
    expected_output.extend(expand(__fastqc_trim__output_done, sample=manager.samples))

__prefix_name__ = join(config["genome"]["genome_directory"], config["genome"]["name"])

if manager.config.genome.do:
    # indexing for bowtie2
    __bowtie2_index_ref__fasta = config["genome"]["fasta_file"]
    __bowtie2_index_ref__output_done = __prefix_name__ + ".1.bt2"
    __bowtie2_index_ref__output_prefix = __prefix_name__
    __bowtie2_index_ref__log = "2-Mapping/logs/bowtie2_ref_indexing.log"
    include: bowtie2_index_dynamic("ref")
    expected_output.extend([__bowtie2_index_ref__output_done])

if manager.config.bowtie2_mapping.do:
    # Decompress fastq.gz file before to run bowtie2
    __unpigz_R1__input = "1-Trimming/%s_R1_trim.fastq.gz" % manager.sample
    __unpigz_R1__output = "1-Trimming/%s_R1_trim.fastq" % manager.sample
    include: dynamic_unpigz("R1", manager)
    __unpigz__output = [__unpigz_R1__output]
    if manager.paired:
        __unpigz_R2__input = "1-Trimming/%s_R2_trim.fastq.gz" % manager.sample
        __unpigz_R2__output = "1-Trimming/%s_R2_trim.fastq" % manager.sample
        include: dynamic_unpigz("R2", manager)
        __unpigz__output += [__unpigz_R2__output]


    # mapping on ref
    __bowtie2_mapping_ref__input = __unpigz__output
    __bowtie2_mapping_ref__index_done = __bowtie2_index_ref__output_done
    # TODO integrer la variable genome dans le nom du bam
    __bowtie2_mapping_ref__sort = "2-Mapping/%s_ref_sort.bam" % manager.sample
    __bowtie2_mapping_ref__bam = "2-Mapping/%s_ref.bam" % manager.sample
    __bowtie2_mapping_ref__logs_err = "2-Mapping/logs/%s_ref_mapping.e" % manager.sample
    __bowtie2_mapping_ref__logs_out = "2-Mapping/logs/%s_ref_mapping.o" % manager.sample
    __bowtie2_mapping_ref__prefix_index = __bowtie2_index_ref__output_prefix
    include: bowtie2_mapping_dynamic("ref", manager)
    expected_output.extend(expand(__bowtie2_mapping_ref__sort, sample=manager.samples))

else:
    __bowtie2_mapping_ref__sort = __data__input

if manager.config.design.spike:
    # indexing for bowtie2
    __prefix_name__ = config["design"]["spike_genome_file"]
    __bowtie2_index_spike__fasta = __prefix_name__
    __bowtie2_index_spike__output_done = __prefix_name__ + ".1.bt2"
    __bowtie2_index_spike__output_prefix = __prefix_name__
    __bowtie2_index_spike__log = "2-Mapping/logs/bowtie2_spike_indexing.log"
    include: bowtie2_index_dynamic("spike")
    expected_output.extend([__bowtie2_index_spike__output_done])

    # mapping on spike
    __bowtie2_mapping_spike__input = __cutadapt__output
    __bowtie2_mapping_spike__index_done = __bowtie2_index_spike__output_done
    __bowtie2_mapping_spike__sort = "2-Mapping/%s_spike_sort.bam" % manager.sample
    __bowtie2_mapping_spike__bam = "2-Mapping/%s_spike.bam" % manager.sample
    __bowtie2_mapping_spike__logs_err = "2-Mapping/logs/%s_spike_mapping.e" % manager.sample
    __bowtie2_mapping_spike__logs_out = "2-Mapping/logs/%s_spike_mapping.o" % manager.sample
    __bowtie2_mapping_spike__prefix_index = __bowtie2_index_spike__output_prefix
    include: bowtie2_mapping_dynamic("spike", manager)
    expected_output.extend(expand(__bowtie2_mapping_spike__sort, sample=manager.samples))

# Mark duplicates
if manager.config.mark_duplicates.do:
    __mark_duplicates__input = __bowtie2_mapping_ref__sort
    __mark_duplicates__output = "3-Deduplication/%s_ref_sort_dedup.bam" % manager.sample
    __mark_duplicates__metrics = "3-Deduplication/%s_ref_sort_dedup.txt" % manager.sample
    __mark_duplicates__log_std = "3-Deduplication/logs/%s_ref_sort_dedup.o" % manager.sample
    __mark_duplicates__log_err = "3-Deduplication/logs/%s_ref_sort_dedup.e" % manager.sample
    include: sm.modules["mark_duplicates"]
    expected_output.extend(expand(__mark_duplicates__output, sample=manager.samples))
else:
    __mark_duplicates__output = __bowtie2_mapping_ref__sort

# Remove blacklist
if manager.config.remove_blacklist.do:
    __remove_blacklist__input = __mark_duplicates__output
    __remove_blacklist__output = "4-NoBlacklist/%s_ref_sort_dedup_NoBlacklist.bam" % manager.sample
    __remove_blacklist__log_std = "4-NoBlacklist/logs/%s_ref_sort_dedup_NoBlacklist.o" % manager.sample
    __remove_blacklist__log_err = "4-NoBlacklist/logs/%s_ref_sort_dedup_NoBlacklist.e" % manager.sample
    include: sm.modules["remove_blacklist"]
    expected_output.extend(expand(__remove_blacklist__output, sample=manager.samples))
else:
    __remove_blacklist__output = __mark_duplicates__output


# PhantomPeakQualTools rule
__spp__input = "4-NoBlacklist/{IP}_{REP}_ref_sort_dedup_NoBlacklist.bam"
__spp__output_pdf = "5-PhantomPeakQualTools/{IP}_{REP}_ref_sort_dedup_NoBlacklist_phantom.pdf"
__spp__metrics = "5-PhantomPeakQualTools/{IP}_{REP}_ref_sort_dedup_NoBlacklist_phantom.txt"
__spp__log_std = "5-PhantomPeakQualTools/logs/{IP}_{REP}_phantom.o"
__spp__log_err = "5-PhantomPeakQualTools/logs/{IP}_{REP}_phantom.e"
expected_output.extend(expand(__spp__metrics, IP=list(design['IP_NAME']), REP=rep))
include: sm.modules["spp"]


ppr = ['PPR1', 'PPR2']
spr = ['SPR1', 'SPR2']
model = manager.config.peak_calling.model_choice

# preIDR rules
# run preIDR on INPUT
if len(INPUT_REP) > 0:
    __preIDR_INPUT__input_bam = expand("4-NoBlacklist/{{INPUT}}_{REP}_ref_sort_dedup_NoBlacklist.bam", REP = rep)
    __preIDR_INPUT__case = "Pool"
    __preIDR_INPUT__log = "4-NoBlacklist/logs/{INPUT}_preIDR_input.o"
    __preIDR_INPUT__output = "4-NoBlacklist/{INPUT}_Pool_ref_sort_dedup_NoBlacklist.bam"
    include: preIDR_dynamic("INPUT")
    #expected_output.extend(expand(__preIDR_INPUT__output, INPUT=INPUT_REP))

if len(IP_REP) > 0:
    # run SPR
    __preIDR_SPR__input_bam = expand("4-NoBlacklist/{{IP}}_{REP}_ref_sort_dedup_NoBlacklist.bam", REP = rep)
    __preIDR_SPR__case = "SPR"
    __preIDR_SPR__log = "4-NoBlacklist/logs/{IP}_preIDR_SPR.o"
    __preIDR_SPR__output = expand("4-NoBlacklist/{{IP}}_{SPR}_sort_dedup_NoBlacklist.bam", SPR = spr)

    include: preIDR_dynamic("SPR")
    expected_output.extend(expand(__preIDR_SPR__output, IP=IP_REP))

    # run PPR
    __preIDR_PPR__input_bam = expand("4-NoBlacklist/{{IP}}_{REP}_ref_sort_dedup_NoBlacklist.bam", REP = rep)
    __preIDR_PPR__case = "PPR"
    __preIDR_PPR__log = "4-NoBlacklist/logs/{IP}_preIDR_PPR.o"
    __preIDR_PPR__output =  expand("4-NoBlacklist/{{IP}}_{PPR}_sort_dedup_NoBlacklist.bam", PPR = ppr)
    include: preIDR_dynamic("PPR")
    expected_output.extend(expand(__preIDR_PPR__output, IP=IP_REP))

	#Peak Calling on SPR
    if model in ["narrow"]:
        # add corresponding options
        __macs2_spr__options = "" + config["peak_calling"]['options']
    else:
        __macs2_spr__options = "--broad " + config["peak_calling"]['options']

    if manager.config.peak_calling.no_model:
        __macs2_spr__options += " --nomodel "
        __macs2_spr__shift_file = "5-PhantomPeakQualTools/{SPR}_ref_sort_dedup_NoBlacklist_phantom.txt"
    else:
        __macs2_spr__shift_file = ""
    # no matter which model
    __macs2_spr__input_bam = __preIDR_SPR__output
    ## ATTENTION : si pas de blacklist, nom different
    __macs2_spr__input = __preIDR_INPUT__output
    __macs2_spr__log = "6-PeakCalling/%s/logs/{SPR}_vs_{INPUT}.o" % model
    __macs2_spr__output = "6-PeakCalling/{}/{{SPR}}_vs_{{INPUT}}_peaks.{}Peak".format(model, model)
    __macs2_spr__output_prefix = "6-PeakCalling/%s/{SPR}_vs_{INPUT}" % model
    #expected_output.extend(expand(__macs2_spr__output, zip, SPR=IP_SPR, INPUT=INPUT))
    #include: macs2_dynamic("spr", manager)

# Peak calling

if model in ["narrow", "broad"]:

	#Peak Calling on replicates
    if model in ["narrow"]:
        # add corresponding options
        __macs2_rep__options = "" + config["peak_calling"]['options']
    else:
        __macs2_rep__options = "--broad " + config["peak_calling"]['options']

    if manager.config.peak_calling.no_model:
        __macs2_rep__options += " --nomodel "
        __macs2_rep__shift_file = "5-PhantomPeakQualTools/{IP}_ref_sort_dedup_NoBlacklist_phantom.txt"
    else:
        __macs2_rep__shift_file = ""
    # no matter which model
    __macs2_rep__input_bam = "4-NoBlacklist/{IP}_ref_sort_dedup_NoBlacklist.bam"
    ## ATTENTION : si pas de blacklist, nom different
    __macs2_rep__input = "-c 4-NoBlacklist/{{INPUT}}_{}_ref_sort_dedup_NoBlacklist.bam".format(rep[0])
    __macs2_rep__log = "6-PeakCalling/%s/logs/{IP}_vs_{INPUT}.o" % model
    __macs2_rep__output = "6-PeakCalling/{}/{{IP}}_vs_{{INPUT}}_peaks.{}Peak".format(model, model)
    __macs2_rep__output_prefix = "6-PeakCalling/%s/{IP}_vs_{INPUT}" % model
    expected_output.extend(expand(__macs2_rep__output, zip, IP=IP, INPUT=INPUT))
    include: macs2_dynamic("rep", manager)


else:
    raise ValueError("Invalid choice of model for peak calling. Use either narrow or broad, or set no-model to yes")







# !Reset expected_output variable after multiqc
# Multiqc rule
__multiqc__input = expected_output
__multiqc__input_dir = "."
__multiqc__logs = "multiqc/multiqc.log"
__multiqc__output = config['multiqc']['output-directory'] + "/multiqc_report.html"
#include: sm.modules["multiqc"]
#expected_output = [__multiqc__output]

# Include rule graph for each sample
__rulegraph__input = __snakefile__
__rulegraph__output = "rulegraph/rulegraph.svg"
__rulegraph__mapper = {"fastqc_samples": "fastqc_samples/"}
include: sm.modules['rulegraph']
expected_output.extend([__rulegraph__output])

# Add Conda
__conda__output = "requirements.txt"
include: sm.modules['conda']  # Create requirements.txt(dependencies)
expected_output.extend([__conda__output])

# Those rules takes a couple of seconds so no need for a cluster
localrules: conda, rulegraph

rule chipseq:
    input: expected_output

onsuccess:
    import os
    # Create plots about stats
    sm.plot_stats(N=len(manager.samples))

    # Main directory
    report_dir_format = "%(proj)s/report_rnaseq_%(proj)s"
    for proj in manager.samples.keys():
        report_dir = report_dir_format % {"proj": proj}
        try:os.mkdir(report_dir)
        except:pass

        shell("cp %s %s" % (__snakefile__, report_dir))
        #shell("cp rulegraph.svg %s/rulegraph.svg" % (report_dir))
        shell("cp config.yaml %s" % report_dir)
        shell("cp requirements.txt %s" % report_dir)
        shell("cp snakemake_stats.png %s" % report_dir)
        try: os.mkdir("cluster_logs")
        except:pass

        try: shell("mv slurm* cluster_logs/")
        except: pass

        # Create a cleanup python file to clean a sub-directory
        sm.create_cleanup(proj)

    sm.OnSuccess()() # create instance to create main cleanup


onerror:
    print("An error occurred. See message above.")
