"""ATAC-seq pipeline

Affiliation: Institut Pasteur @ 2018

This pipeline is part of Sequana software (sequana.readthedocs.io)
"""
import os
import sequana
from os.path import join
from sequana import snaketools as sm
sm.init("atac-seq.rules", globals())


# This must be defined before the include
configfile: "config.yaml"
__snakefile__ = srcdir(__snakefile__)

# Generic include of some dynamic modules
exec(open(sequana.modules["fastqc_dynamic"], "r").read())


manager = sm.PipelineManager("atac-seq", config)

__data__input = manager.getrawdata()


__prefix_name__ = join(config["genome"]["genome_directory"], config["genome"]["name"])

if manager.config.genome.do:
    # create sequence dict file
    __create_sequence_dictionary__reference = config["genome"]["fasta_file"]
    __create_sequence_dictionary__output = config["genome"]["fasta_file"] + ".dict"
    __create_sequence_dictionary__log = "logs/indexing/create_sequence_dictionary.log"
    include: sm.modules["create_sequence_dictionary"]

    # indexing for bowtie2
    __bowtie2_index__fasta = config["genome"]["fasta_file"]
    __bowtie2_index__output_done = __prefix_name__ + ".1.bt2"
    __bowtie2_index__output_prefix = __prefix_name__
    __bowtie2_index__log = "logs/indexing/bowtie2_genome.log"
    include: sm.modules["bowtie2_index"]


    #output index
    __bowtie2_index__ = __bowtie2_index__output_prefix
    __sequence_dictionary__ = __create_sequence_dictionary__output
    expected_output.extend([__create_sequence_dictionary__output,__bowtie2_index__output_done])

else:
    __bowtie2_index__ =__prefix_name__
    __bowtie2_index__output_done = __prefix_name__ + ".1.bt2"
    __sequence_dictionary__ = config["genome"]["fasta_file"] + ".dict"



# FASTQC on input data set
__fastqc_samples__input_fastq = __data__input
__fastqc_samples__output_done = manager.getname("fastqc_samples", ".done")
__fastqc_samples__wkdir       = manager.getwkdir("fastqc_samples")
__fastqc_samples__log         = "%s/fastqc_samples/fastqc.log" % manager.sample
include: fastqc_dynamic("samples", manager)
expected_output.extend(expand(__fastqc_samples__output_done, sample=manager.samples))




if manager.config.cutadapt.do:
    adapter_tool = manager.config.cutadapt.tool_choice

    from sequana.adapters import _get_registered_adapters as registered
    from sequana.adapters import get_sequana_adapters

    # Users may provide TruSeq, Nextera, PCRFree or other registered adapters
    fwd = manager.config.cutadapt.fwd
    if isinstance(fwd, str) and fwd in registered():
        filename = "file:"+ get_sequana_adapters(fwd, "fwd")
        manager.config.cutadapt.fwd = filename

    rev = manager.config.cutadapt.rev
    if isinstance(rev, str) and rev in registered():
        filename = "file:"+ get_sequana_adapters(rev, "revcomp")
        manager.config.cutadapt.rev = filename

    if adapter_tool in ["cutadapt", "atropos"]:
        adapter_tool = "cutadapt"
        __cutadapt__input_fastq = __data__input
        __cutadapt__wkdir = manager.getwkdir("cutadapt")
        __cutadapt__output = [manager.getname("cutadapt", "_R1_.cutadapt.fastq.gz")]
        if manager.paired:
            __cutadapt__output += [manager.getname("cutadapt", "_R2_.cutadapt.fastq.gz")]

        # Set the fwd and rev adapters
        __cutadapt__fwd = manager.config.cutadapt.fwd
        __cutadapt__rev = manager.config.cutadapt.rev

        __cutadapt__design = manager.config.cutadapt.design_file
        __cutadapt__design_adapter = manager.config['cutadapt']['adapter_choice']
        __cutadapt__options = manager.config.cutadapt.options
        __cutadapt__mode = manager.config.cutadapt.mode
        __cutadapt__log = "%s/logs/cutadapt/cutadapt.txt" % manager.sample
        __cutadapt__sample = manager.sample
        include: sm.modules["cutadapt"]

    else:
        raise ValueError("Invalid choice of cutadapt:tool in config file. Use either clean_ngs or cutadapt")


# FASTQC on input data set
__fastqc_filtered__input_fastq = __cutadapt__output
__fastqc_filtered__output_done = manager.getname("fastqc_filtered", ".done")
__fastqc_filtered__wkdir       = manager.getwkdir("fastqc_filtered")
__fastqc_filtered__log         = "%s/fastqc_filtered/fastqc.log" % manager.sample
include: fastqc_dynamic("filtered", manager)
expected_output.extend(expand(__fastqc_filtered__output_done, sample=manager.samples))

# Mapping with bowtie2
if manager.config.bowtie2_mapping.do:
    __bowtie2_mapping__input = __cutadapt__output
    __bowtie2_mapping__index_done = __bowtie2_index__output_done
    __bowtie2_mapping__sort = manager.getname("bowtie2_mapping", ".sorted.bam")
    __bowtie2_mapping__bam = manager.getname("bowtie2_mapping", ".bam")
    __bowtie2_mapping__logs_err = "%s/logs/bowtie2/stderr.logs" % manager.sample
    __bowtie2_mapping__logs_out = "%s/logs/bowtie2/stdout.logs" % manager.sample
    __bowtie2_mapping__prefix_index = __bowtie2_index__
    include: sm.modules["bowtie2_mapping"]
    expected_output.extend(expand(__bowtie2_mapping__sort, sample=manager.samples))

# Add Read group on BAM files
__add_read_group__input = __bowtie2_mapping__sort
__add_read_group__output = manager.getname("add_read_group/", "_RG_sorted.bam")
__add_read_group__log_err = "%s/logs/AddOrReplaceReadGroups/stderr.logs" % manager.sample
__add_read_group__log_std ="%s/logs/AddOrReplaceReadGroups/stdout.logs" % manager.sample
__add_read_group__rg = "ID=%s LB=%s PL=%s PU=%s SM=%s" % (manager.sample, manager.sample, manager.config.sequencing.platform, manager.config.sequencing.flowcell, manager.sample)
include: sm.modules["add_read_group"]


# Mark duplicates
__mark_duplicates__input = __add_read_group__output
__mark_duplicates__output = manager.getname("mark_duplicates", ".bam")
__mark_duplicates__metrics = manager.getname("mark_duplicates", ".metrics")
__mark_duplicates__log_std = "%s/logs/mark_duplicates/stdout.logs" % manager.sample
__mark_duplicates__log_err =  "%s/logs/mark_duplicates/stderr.logs" % manager.sample
include: sm.modules["mark_duplicates"]
expected_output.extend(expand(__mark_duplicates__output, sample=manager.samples))


__CollectInsertSizeMetrics__input = __mark_duplicates__output
__CollectInsertSizeMetrics__output = manager.getname("CollectInsertSizeMetrics", "_insertSize.pdf")
__CollectInsertSizeMetrics__metrics = manager.getname("CollectInsertSizeMetrics", ".metrics")
__CollectInsertSizeMetrics__log_std = "%s/logs/InsertSizeMetrics/stdout.logs" % manager.sample
__CollectInsertSizeMetrics__log_err = "%s/logs/InsertSizeMetrics/stderr.logs" % manager.sample
include: sm.modules["CollectInsertSizeMetrics"]
expected_output.extend(expand(__CollectInsertSizeMetrics__output, sample=manager.samples))

# TODO split data as NUC-free and all ?


# TODO prendre en compte le design experimental
__macs2__ = __mark_duplicates__output
__macs2__input_bam = "None"
__macs2__log = "%s/logs/macs2/peak_calling.err" % manager.sample
__macs2__output = manager.getname("macs2", "Peaks")
__macs2__output_done = manager.getname("macs2", ".done")
include: sm.modules["macs2"]
expected_output.extend(expand(__macs2__output, sample=manager.samples))


if manager.paired:
    # BamPEFragmentSize (part of Deeptools)
    __BamPEFragmentSize__input_bams = expand(__bowtie2_mapping__sort)
    __BamPEFragmentSize__binsize = 10000
    __BamPEFragmentSize__logs = "logs/deeptools/BamPEFragmentSize.err"
    __BamPEFragmentSize__output = manager.getname("deeptools", "BamPEFragmentSize.png")
    include: sm.modules["BamPEFragmentSize"]
    expected_output.extend(expand(__BamPEFragmentSize__output, sample=manager.samples))

if manager.config.coverage.do:
    #Bam coverage (part of Deeptools)
    __bamCoverage__input = __mark_duplicates__output
    __bamCoverage__output = manager.getname("BamCoverage", "_norm.bw")
    __bamCoverage__log = "logs/deeptools/BamCoverage_%s.err." % manager.sample
    include: sm.modules["bamCoverage"]
    expected_output.extend(expand(__bamCoverage__output, sample=manager.samples))

if manager.config.correlation.do:
    # plot correlation (part of Deeptools)
    __multiBamSummary__input = expand(__mark_duplicates__output)
    __multiBamSummary__log = "logs/deeptools/BamSummary.err"
    __multiBamSummary__output = "BamSummary.npz"
    include: sm.modules["multiBamSummary"]
    __plotCorrelation__input = __multiBamSummary__output
    __plotCorrelation__output = manager.getname("deeptools", "scatterplot_correlation.svg")
    __plotCorrelation__log = "logs/deeptools/plotCorrelation.err"
    expected_output.extend(expand(__bamCoverage__output, sample=manager.samples))
    include: sm.modules["plotCorrelation"]


if manager.config.heatmap.do:
    # compute Matrix
    __computeMatrix__wig = expand(__bamCoverage__output)
    __computeMatrix__log = "logs/deeptools/computeMatrix.err"
    __computeMatrix__output = manager.getname("deeptools", "matrixHeatmap.gz")
    include: sm.modules["computeMatrix"]
    # plotHeatmap
    __plotHeatmap__input = __computeMatrix_output
    __plotHeatmap__log = "logs/deeptools/plotHeatmap.err"
    __plotHeatmap__output = manager.getname("deeptools", "Heatmap_plot.png")
    include: sm.modules["plotHeatmap"]
    expected_output.extend(expand(__plotHeatmap_output, sample=manager.samples))

# !Reset expected_output variable after multiqc
# Multiqc rule
__multiqc__input = expected_output
__multiqc__input_dir = "."
__multiqc__logs = "multiqc/multiqc.log"
__multiqc__output = config['multiqc']['output-directory'] + "/multiqc_report.html"
include: sm.modules["multiqc"]
expected_output = [__multiqc__output]



# Include rule graph for each sample
__rulegraph__input = __snakefile__
__rulegraph__output = "rulegraph/rulegraph.svg"
__rulegraph__mapper = {"fastqc_samples": "fastqc_samples/"}
include: sm.modules['rulegraph']
expected_output.extend([__rulegraph__output])


# Add Conda
__conda__output = "requirements.txt"
include: sm.modules['conda']   # Create requirements.txt(dependencies)
expected_output.extend([__conda__output])



# Those rules takes a couple of seconds so no need for a cluster
localrules: conda, rulegraph

rule ataseq:
    input: expected_output


onsuccess:
    import os
    # Create plots about stats
    sm.plot_stats(N=len(manager.samples))

    # Main directory
    report_dir_format = "%(proj)s/report_atacseq_%(proj)s"
    for proj in manager.samples.keys():
        report_dir = report_dir_format % {"proj": proj}
        try:os.mkdir(report_dir)
        except:pass

        shell("cp %s %s" % (__snakefile__, report_dir))
        #shell("cp rulegraph.svg %s/rulegraph.svg" % (report_dir))
        shell("cp config.yaml %s" % report_dir)
        shell("cp requirements.txt %s" % report_dir)
        shell("cp snakemake_stats.png %s" % report_dir)
        try: os.mkdir("cluster_logs")
        except:pass

        try: shell("mv slurm* cluster_logs/")
        except: pass

        # Create a cleanup python file to clean a sub-directory
        sm.create_cleanup(proj)

    sm.OnSuccess()() # create instance to create main cleanup


onerror:
    print("An error occurred. See message above.")
