"""ATAC-seq pipeline

Affiliation: Institut Pasteur @ 2016

This pipeline is part of Sequana software (sequana.readthedocs.io)
"""
import os
import sequana
from sequana import snaketools as sm
sm.init("rnaseq.rules", globals())


# This must be defined before the include
configfile: "config.yaml"
__snakefile__ = srcdir(__snakefile__)

# Generic include of some dynamic modules
exec(open(sequana.modules["fastqc_dynamic"], "r").read())


manager = sm.PipelineManager("atac-seq", config)

__data__input = manager.getrawdata()


TODO = "todo"

# FASTQC on input data set
__fastqc_samples__input_fastq = __data__input
__fastqc_samples__output_done = manager.getname("fastqc_samples", ".done")
__fastqc_samples__wkdir       = manager.getwkdir("fastqc_samples")
__fastqc_samples__log         = "%s/fastqc_samples/fastqc.log" % manager.sample
include: fastqc_dynamic("samples", manager.sample)
expected_output.extend(expand(__fastqc_samples__output_done, sample=manager.samples))



__prefix_name__ = join(config["genome"]["genome_directory"], config["genome"]["name"])

if manager.config.genome.do:
    # create sequence dict file
    __create_sequence_dictionary__reference = config["genome"]["fasta_file"]
    __create_sequence_dictionary__output = config["genome"]["fasta_file"] + ".dict"
    __create_sequence_dictionary__log = "logs/indexing/create_sequence_dictionary.log"
    include: sm.modules["create_sequence_dictionary"]

    # indexing for bowtie2
    __bowtie2_index__fasta = config["genome"]["fasta_file"]
    __bowtie2_index__output_done = __prefix_name__ + ".1.bt2"
    __bowtie2_index__output_prefix = __prefix_name__
    __bowtie2_index__log = "logs/indexing/bowtie2_genome.log"
    include: sm.modules["bowtie2_index"]


    #output index
    __bowtie2_index__ = __bowtie2_index__output_prefix
    __sequence_dictionary__ = __create_sequence_dictionary__output
    expected_output.extend([__create_sequence_dictionary__output,__bowtie2_index__output_done])

else:
    __bowtie2_index__ =__prefix_name__
    __bowtie2_index__output_done = __prefix_name__ + ".1.bt2"
    __sequence_dictionary__ = config["genome"]["fasta_file"] + ".dict"






# Perform the adapter removal and trimming
if manager.config['cutadapt']['do']:
    adapter_removal = manager.config['cutadapt']['tool_choice']

    from sequana.adapters import _get_registered_adapters as registered
    from sequana.adapters import get_sequana_adapters

    # Users may provide Nextera, PCRFree, Rubicon or other registered adapters
    fwd = manager.config.cutadapt.fwd
    if isinstance(fwd, str) and fwd in registered():
        filename = "file:"+ get_sequana_adapters(fwd, "fwd")
        manager.config.cutadapt.fwd = filename

    rev = manager.config.cutadapt.rev
    if isinstance(rev, str) and rev in registered():
        filename = "file:"+ get_sequana_adapters(rev, "revcomp")
        manager.config.cutadapt.rev = filename

    if adapter_removal in ["cutadapt", "atropos"]:
        adapter_removal = "cutadapt"
        if manager.config.bwa_mem_phix.do:
            __cutadapt__input_fastq = [x for x in __bwa_bam_to_fastq__fastq_output
                                       if "unmapped" in x]
            __cutadapt__output = [x.replace("bwa_bam_to_fastq",
                                  "cutadapt").replace("unmapped","cutadapt")
                                  for x in __cutadapt__input_fastq]
        else:
            # If the fix is not yet performed, __data__input is a wildcard
            # function so the output must be specified by hand
            __cutadapt__input_fastq = __data__input
            if manager.paired:
                __cutadapt__output = [
                    "{sample}/cutadapt/{sample}_R1_.cutadapt.fastq.gz",
                    "{sample}/cutadapt/{sample}_R2_.cutadapt.fastq.gz"]
            else:
                __cutadapt__output = [
                    "{sample}/cutadapt/{sample}_R1_.cutadapt.fastq.gz"]

        __cutadapt__wkdir = "%s/cutadapt" % manager.sample

        # Set the fwd and rev adapters
        __cutadapt__fwd = manager.config.cutadapt.fwd
        __cutadapt__rev = manager.config.cutadapt.rev

        __cutadapt__design = manager.config.cutadapt.design_file
        __cutadapt__design_adapter = manager.config['cutadapt']['adapter_choice']
        __cutadapt__options = manager.config.cutadapt.options
        __cutadapt__mode = manager.config.cutadapt.mode
        __cutadapt__log = "%s/logs/cutadapt/cutadapt.txt" % manager.sample
        __cutadapt__sample = manager.sample
        include: sm.modules["cutadapt"]
    else:
        raise ValueError("trimming must be either cutadapt or atropos")

# FASTQC on input data set
__fastqc_filtered__input_fastq = __cutadapt__output
__fastqc_filtered__output_done = manager.getname("fastqc_filtered", ".done")
__fastqc_filtered__wkdir       = manager.getwkdir("fastqc_filtered")
__fastqc_filtered__log         = "%s/fastqc_filtered/fastqc.log" % manager.sample
include: fastqc_dynamic("filtered", manager.sample)
expected_output.extend(expand(__fastqc_filtered__output_done, sample=manager.samples))

# Mapping with bowtie2
__bowtie2_mapping__input = __cutadapt__output
__bowtie2_mapping__index_done = __bowtie2_index__output_done
__bowtie2_mapping__sort = manager.getname("bowtie2_mapping", ".sorted.bam")
__bowtie2_mapping__logs_err = "%s/logs/bowtie2/stderr.logs" % manager.sample
__bowtie2_mapping__logs_out = "%s/logs/bowtie2/stdout.logs" % manager.sample
__bowtie2_mapping__prefix index = __prefix_name__
__bowtie2_mapping__sam = manager.getname("bowtie2_mapping", ".sam")


# Add Read group on BAM files
__add_read_group__input = __mapping_output
__add_read_group__output = manager.getname("add_read_group/", "_RG_sorted.bam")
__add_read_group__log_err = "%s/logs/AddOrReplaceReadGroups/stderr.logs" % manager.sample
__add_read_group__log_std ="%s/logs/AddOrReplaceReadGroups/stdout.logs" % manager.sample
__add_read_group__rg = "ID=%s LB=%s PL=%s PU=%s SM=%s" % (manager.sample, manager.sample, manager.config.sequencing.platform, manager.config.sequencing.flowcell, manager.sample)
include: sm.modules["add_read_group"]

# Mark duplicates
__mark_duplicates__input = __add_read_group__output
__mark_duplicates__output = manager.getname("mark_duplicates", ".bam")
__mark_duplicates__metrics = manager.getname("mark_duplicates", ".metrics")
__mark_duplicates__log_std = "%s/logs/mark_duplicates/stdout.logs" % manager.sample
__mark_duplicates__log_err =  "%s/logs/mark_duplicates/stderr.logs" % manager.sample
include: sm.modules["mark_duplicates"]
expected_output.extend(expand(__mark_duplicates__output, sample=manager.samples))


__CollectInsertSizeMetrics__input = __mark_duplicates__output
__CollectInsertSizeMetrics__output = manager.getname("CollectInsertSizeMetrics", "_insertSize.pdf")
__CollectInsertSizeMetrics__metrics = manager.getname("CollectInsertSizeMetrics", ".metrics")
__CollectInsertSizeMetrics__log_std = "%s/logs/InsertSizeMetrics/stdout.logs" % manager.sample
__CollectInsertSizeMetrics__log_err = "%s/logs/InsertSizeMetrics/stderr.logs" % manager.sample
include: sm.modules["CollectInsertSizeMetrics"]
expected_output.extend(expand(__CollectInsertSizeMetrics__output, sample=manager.samples))


# TODO prendre en compte le design experimental
__macs2__input = __mark_duplicates__output
__macs2__input_bam = ## relative to INPUT bam (or Control condition)
__macs2__log_std = "%s/logs/macs2/stdout.logs" % manager.sample
__macs2__log_err = "%s/logs/macs2/stderr.logs" % manager.sample
__macs2__output = #Be carefull, the output is a prefix
include: sm.modules["macs2"]
expected_output.extend(expand(__macs2__output, sample=manager.samples))


# BamPEFragmentSize (part of Deeptools)
__BamPEFragmentSize__input_bams = expand(__bowtie2_mapping__sort)
__BamPEFragmentSize__binsize = 10000
__BamPEFragmentSize__logs = "%s/logs/deeptools/BamPEFragmentSize.err" % manager.sample
__BamPEFragmentSize__output =
include: sm.modules["BamPEFragmentSize"]
expected_output.extend(expand(__BamPEFragmentSize__output, sample=manager.samples))


#Bam coverage (part of Deeptools)
__bamCoverage__input = __mark_duplicates__output
__bamCoverage__output = manager.getname("BamCoverage", "_norm.bw")
__bamCoverage__log = "%s/logs/deeptools/BamCoverage.err." % manager.sample
include: sm.modules["bamCoverage"]
expected_output.extend(expand(__bamCoverage__output, sample=manager.samples))


# plot correlation (part of Deeptools)
__multiBamSummary__input = expand(__mark_duplicates__output)
__multiBamSummary__log = "%s/logs/deeptools/BamSummary.err" % manager.sample
__multiBamSummary__output = "BamSummary.npz"
__plotCorrelation__input = __multiBamSummary__output
__plotCorrelation__output = "scatterplot_correlation.svg"
__plotCorrelation__log = "%s/logs/deeptools/plotCorrelation.err" % manager.sample



# !!!!!!!!!!!!!!!!!!! Reset expected_output variable after multiqc
# Multiqc rule
__multiqc__input = expected_output
__multiqc__input_dir = "."
__multiqc__logs = "multiqc/multiqc.log"
__multiqc__output = config['multiqc']['output-directory'] + "/multiqc_report.html"
include: sm.modules["multiqc"]
expected_output = [__multiqc__output]


# Include rule graph for each sample
__rulegraph__input = __snakefile__
__rulegraph__output = "rulegraph/rulegraph.svg"
__rulegraph__mapper = {"fastqc_samples": "fastqc_samples/"}
include: sm.modules['rulegraph']
expected_output.extend([__rulegraph__output])


# Add Conda
__conda__output = "requirements.txt"
include: sm.modules['conda']   # Create requirements.txt(dependencies)
expected_output.extend([__conda__output])

# Those rules takes a couple of seconds so no need for a cluster
localrules:  conda, rulegraph

rule atacseq:
    input: expected_output


onsuccess:
    import os
    # Create plots about stats
    sm.plot_stats(N=len(manager.samples))

    # Main directory
    report_dir_format = "%(proj)s/report_atac-seq_%(proj)s"
    for proj in manager.samples.keys():
        report_dir = report_dir_format % {"proj": proj}
        try:os.mkdir(report_dir)
        except:pass

        shell("cp %s %s" % (__snakefile__, report_dir))
        shell("cp rulegraph.svg %s/rulegraph.svg" % (report_dir))
        shell("cp config.yaml %s" % report_dir)
        shell("cp requirements.txt %s" % report_dir)
        shell("cp snakemake_stats.png %s" % report_dir)

        shell('cp -r %s/fastqc_*/ %s' % (proj, report_dir))
        shell('cp -r %s/cutadapt/ %s' % (proj, report_dir))

        """
        # Commented by TC Avril 2017 since reporting package is now removed
        # and create_cleanup will be deprecated
        from sequana.reporting.report_summary import SequanaSummary
        summary = SequanaSummary(proj, directory=report_dir,
            output_filename="summary.html",
            snakefile=__snakefile__, configfile=report_dir+"/config.yaml",
            manager=manager)
        summary.create_report()

        # Create a cleanup python file to clean a sub-directory
        sm.create_cleanup(proj)
        """

    #sm.create_recursive_cleanup()
    #sm.message("Done. To further cleanup the directory, type \n python .sequana_cleanup.py")

onerror:
    print("An error occurred. See message above.")


